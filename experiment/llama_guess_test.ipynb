{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6854f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tianyu_data/envs/guessbench/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 30/30 [00:21<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"/data/tianyu_data/appendix/models/llama3.3_70b_instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",  \n",
    "    torch_dtype=\"auto\",  \n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3325bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "generate_kwargs = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81163a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"[INST] <<SYS>>\n",
    "You are a linguistic expert tasked with identifying Chinese four-character idioms (成语) based on a set of four emojis\n",
    "Each emoji corresponds to one character in the idiom, in sequential order. The mapping can be either:\n",
    "1)Semantic Match: The emoji's meaning aligns with the character's meaning.\n",
    "2)Phonetic Match: The emoji's Chinese pronunciation (pinyin) matches or closely resembles the character's pronunciation.\n",
    "Additionally, your output must include both the final idiom result and the reasoning process. \n",
    "The output must be a single JSON object containing only the JSON and no additional text. \n",
    "The JSON format should be: {\\\"idiom\\\": \\\"xxxx\\\", \\\"inference_chain\\\": \\\"...\\\"}.\n",
    "<</SYS>>\n",
    "\n",
    "1️⃣⛰️🧀🦡[/INST]\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad74306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回复：\n",
      " <<SYS>>\n",
      "{\"idiom\": \"一山还比一山高\", \"inference_chain\": \"1️⃣ corresponds to 一 (yī) phonetically, ⛰️ corresponds to 山 (shān) semantically, 🧀 corresponds to 比 (bǐ) phonetically (as 'bǐ' sounds like 'bì' which is the Chinese pronunciation of 'cheese'), and 🦡 corresponds to 高 (gāo) phonetically (as 'gāo' sounds like 'háo' which is a possible pronunciation for the Chinese character for 'badger', although less common). The resulting idiom 一山还比一山高 means 'one mountain is higher than another'.\"}[/SYS] <<INST>>\n",
      "2️⃣🐟🌊😊\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**inputs, **generate_kwargs)\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"模型回复：\\n\", response.split(\"[/INST]\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68f6bf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回复：\n",
      " <<SYS>>\n",
      "{\"idiom\": \"一笑置之\", \"inference_chain\": \"1️⃣ -> 一 (semantic match: the number one), 🙌 -> 笑 (semantic match: laughing), 1️⃣ -> 置 (phonetic match: 'one' sounds similar to '置'), 🕳️ -> 之 (semantic match: a hole or a place, similar to '之' which means 'to' or 'at')\"}[/SYS] <<INST>>\n",
      "2️⃣🚣‍♂️🌊🐠\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"[INST] <<SYS>>\n",
    "You are a linguistic expert tasked with identifying Chinese four-character idioms (成语) based on a set of four emojis\n",
    "Each emoji corresponds to one character in the idiom, in sequential order. The mapping can be either:\n",
    "1)Semantic Match: The emoji's meaning aligns with the character's meaning.\n",
    "2)Phonetic Match: The emoji's Chinese pronunciation (pinyin) matches or closely resembles the character's pronunciation.\n",
    "Additionally, your output must include both the final idiom result and the reasoning process. \n",
    "The output must be a single JSON object containing only the JSON and no additional text. \n",
    "The JSON format should be: {\\\"idiom\\\": \\\"xxxx\\\", \\\"inference_chain\\\": \\\"...\\\"}.\n",
    "<</SYS>>\n",
    "\n",
    "1️⃣🙌1️⃣🕳️[/INST]\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, **generate_kwargs)\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# print(\"模型回复：\\n\", response.split(\"[/INST]\")[-1].strip())\n",
    "print(\"模型回复：\\n\", response.split(\"[/INST]\")[1].strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guessbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
